2023-07-04 23:35:33,716 	 [INFO | spark_stream_table1.py:8] > Importing Spark and Mysql packages...
2023-07-04 23:35:34,282 	 [INFO | spark_stream_table1.py:14] > Successfully imported Spark and Mysql packages!
2023-07-04 23:35:34,282 	 [INFO | spark_stream_table1.py:19] > Importing Configuration Variables...
2023-07-04 23:35:34,304 	 [INFO | tools.py:31] > .
2023-07-04 23:35:34,304 	 [INFO | tools.py:32] > ..
2023-07-04 23:35:34,304 	 [INFO | tools.py:33] > Repo is starting...
2023-07-04 23:35:34,304 	 [INFO | tools.py:34] > Configuration file is read successfully.
2023-07-04 23:35:34,304 	 [INFO | tools.py:106] > Adjusted MySQL Connection in order to load the data.
2023-07-04 23:35:34,304 	 [INFO | tools.py:45] > Adjusted KafkaConnection in order to move the data.
2023-07-04 23:35:34,304 	 [INFO | spark_stream_table1.py:31] > Successfully imported Configuration Variables!
2023-07-04 23:35:35,972 	 [DEBUG | java_gateway.py:163] > GatewayClient.address is deprecated and will be removed in version 1.0. Use GatewayParameters instead.
2023-07-04 23:35:35,978 	 [DEBUG | clientserver.py:501] > Command to send: A
f450232a2d3ec9809c7fca2842ad5d64f417746dc509c99223a1f02aa0d97c27

2023-07-04 23:35:35,989 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,990 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.SparkConf
e

2023-07-04 23:35:35,991 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,991 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.api.java.*
e

2023-07-04 23:35:35,991 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,992 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.api.python.*
e

2023-07-04 23:35:35,992 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,996 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.ml.python.*
e

2023-07-04 23:35:35,996 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,996 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.mllib.api.python.*
e

2023-07-04 23:35:35,997 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,997 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.resource.*
e

2023-07-04 23:35:35,997 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,998 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.sql.*
e

2023-07-04 23:35:35,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,998 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.sql.api.python.*
e

2023-07-04 23:35:35,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,998 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
org.apache.spark.sql.hive.*
e

2023-07-04 23:35:35,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:35,999 	 [DEBUG | clientserver.py:501] > Command to send: j
i
rj
scala.Tuple2
e

2023-07-04 23:35:36,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,000 	 [DEBUG | clientserver.py:501] > Command to send: r
u
SparkConf
rj
e

2023-07-04 23:35:36,021 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkConf
2023-07-04 23:35:36,022 	 [DEBUG | clientserver.py:501] > Command to send: i
org.apache.spark.SparkConf
bTrue
e

2023-07-04 23:35:36,029 	 [DEBUG | clientserver.py:512] > Answer received: !yro0
2023-07-04 23:35:36,030 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
set
sspark.app.name
sSpark Kafka Streaming
e

2023-07-04 23:35:36,035 	 [DEBUG | clientserver.py:512] > Answer received: !yro1
2023-07-04 23:35:36,035 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
set
sspark.master
slocal[1]
e

2023-07-04 23:35:36,036 	 [DEBUG | clientserver.py:512] > Answer received: !yro2
2023-07-04 23:35:36,036 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
set
sspark.jars.packages
sorg.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1
e

2023-07-04 23:35:36,037 	 [DEBUG | clientserver.py:512] > Answer received: !yro3
2023-07-04 23:35:36,037 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.serializer.objectStreamReset
e

2023-07-04 23:35:36,038 	 [DEBUG | clientserver.py:512] > Answer received: !ybfalse
2023-07-04 23:35:36,039 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
set
sspark.serializer.objectStreamReset
s100
e

2023-07-04 23:35:36,039 	 [DEBUG | clientserver.py:512] > Answer received: !yro4
2023-07-04 23:35:36,039 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.rdd.compress
e

2023-07-04 23:35:36,040 	 [DEBUG | clientserver.py:512] > Answer received: !ybfalse
2023-07-04 23:35:36,040 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
set
sspark.rdd.compress
sTrue
e

2023-07-04 23:35:36,040 	 [DEBUG | clientserver.py:512] > Answer received: !yro5
2023-07-04 23:35:36,040 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.master
e

2023-07-04 23:35:36,040 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:36,041 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.app.name
e

2023-07-04 23:35:36,041 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:36,041 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.master
e

2023-07-04 23:35:36,041 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:36,041 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
get
sspark.master
e

2023-07-04 23:35:36,043 	 [DEBUG | clientserver.py:512] > Answer received: !yslocal[1]
2023-07-04 23:35:36,044 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.app.name
e

2023-07-04 23:35:36,044 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:36,044 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
get
sspark.app.name
e

2023-07-04 23:35:36,045 	 [DEBUG | clientserver.py:512] > Answer received: !ysSpark Kafka Streaming
2023-07-04 23:35:36,045 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
contains
sspark.home
e

2023-07-04 23:35:36,045 	 [DEBUG | clientserver.py:512] > Answer received: !ybfalse
2023-07-04 23:35:36,045 	 [DEBUG | clientserver.py:501] > Command to send: c
o0
getAll
e

2023-07-04 23:35:36,046 	 [DEBUG | clientserver.py:512] > Answer received: !yto6
2023-07-04 23:35:36,046 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,046 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,046 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i0
e

2023-07-04 23:35:36,046 	 [DEBUG | clientserver.py:512] > Answer received: !yro7
2023-07-04 23:35:36,046 	 [DEBUG | clientserver.py:501] > Command to send: c
o7
_1
e

2023-07-04 23:35:36,047 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.files
2023-07-04 23:35:36,047 	 [DEBUG | clientserver.py:501] > Command to send: c
o7
_2
e

2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:512] > Answer received: !ysfile:///Users/eodemir/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar,file:///Users/eodemir/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///Users/eodemir/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,file:///Users/eodemir/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,file:///Users/eodemir/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,file:///Users/eodemir/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///Users/eodemir/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,file:///Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,file:///Users/eodemir/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar
2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i1
e

2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:512] > Answer received: !yro8
2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:501] > Command to send: c
o8
_1
e

2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.app.name
2023-07-04 23:35:36,048 	 [DEBUG | clientserver.py:501] > Command to send: c
o8
_2
e

2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:512] > Answer received: !ysSpark Kafka Streaming
2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i2
e

2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:512] > Answer received: !yro9
2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:501] > Command to send: c
o9
_1
e

2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.rdd.compress
2023-07-04 23:35:36,049 	 [DEBUG | clientserver.py:501] > Command to send: c
o9
_2
e

2023-07-04 23:35:36,054 	 [DEBUG | clientserver.py:512] > Answer received: !ysTrue
2023-07-04 23:35:36,054 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,056 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,056 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i3
e

2023-07-04 23:35:36,056 	 [DEBUG | clientserver.py:512] > Answer received: !yro10
2023-07-04 23:35:36,056 	 [DEBUG | clientserver.py:501] > Command to send: c
o10
_1
e

2023-07-04 23:35:36,057 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.serializer.objectStreamReset
2023-07-04 23:35:36,057 	 [DEBUG | clientserver.py:501] > Command to send: c
o10
_2
e

2023-07-04 23:35:36,057 	 [DEBUG | clientserver.py:512] > Answer received: !ys100
2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i4
e

2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:512] > Answer received: !yro11
2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:501] > Command to send: c
o11
_1
e

2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.submit.pyFiles
2023-07-04 23:35:36,058 	 [DEBUG | clientserver.py:501] > Command to send: c
o11
_2
e

2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:512] > Answer received: !ys/Users/eodemir/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.1.jar,/Users/eodemir/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.1.jar,/Users/eodemir/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar,/Users/eodemir/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,/Users/eodemir/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,/Users/eodemir/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,/Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,/Users/eodemir/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,/Users/eodemir/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,/Users/eodemir/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,/Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,/Users/eodemir/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,/Users/eodemir/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar
2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i5
e

2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:512] > Answer received: !yro12
2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:501] > Command to send: c
o12
_1
e

2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.app.submitTime
2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:501] > Command to send: c
o12
_2
e

2023-07-04 23:35:36,059 	 [DEBUG | clientserver.py:512] > Answer received: !ys1688502935888
2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i6
e

2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:512] > Answer received: !yro13
2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:501] > Command to send: c
o13
_1
e

2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.submit.deployMode
2023-07-04 23:35:36,060 	 [DEBUG | clientserver.py:501] > Command to send: c
o13
_2
e

2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:512] > Answer received: !ysclient
2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i7
e

2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:512] > Answer received: !yro14
2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:501] > Command to send: c
o14
_1
e

2023-07-04 23:35:36,061 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.jars.packages
2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:501] > Command to send: c
o14
_2
e

2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:512] > Answer received: !ysorg.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1
2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i8
e

2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:512] > Answer received: !yro15
2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:501] > Command to send: c
o15
_1
e

2023-07-04 23:35:36,062 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.ui.showConsoleProgress
2023-07-04 23:35:36,063 	 [DEBUG | clientserver.py:501] > Command to send: c
o15
_2
e

2023-07-04 23:35:36,063 	 [DEBUG | clientserver.py:512] > Answer received: !ystrue
2023-07-04 23:35:36,063 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,063 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,063 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i9
e

2023-07-04 23:35:36,063 	 [DEBUG | clientserver.py:512] > Answer received: !yro16
2023-07-04 23:35:36,064 	 [DEBUG | clientserver.py:501] > Command to send: c
o16
_1
e

2023-07-04 23:35:36,064 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.master
2023-07-04 23:35:36,064 	 [DEBUG | clientserver.py:501] > Command to send: c
o16
_2
e

2023-07-04 23:35:36,064 	 [DEBUG | clientserver.py:512] > Answer received: !yslocal[1]
2023-07-04 23:35:36,064 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,065 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,065 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i10
e

2023-07-04 23:35:36,065 	 [DEBUG | clientserver.py:512] > Answer received: !yro17
2023-07-04 23:35:36,066 	 [DEBUG | clientserver.py:501] > Command to send: c
o17
_1
e

2023-07-04 23:35:36,066 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.repl.local.jars
2023-07-04 23:35:36,066 	 [DEBUG | clientserver.py:501] > Command to send: c
o17
_2
e

2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:512] > Answer received: !ysfile:///Users/eodemir/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar,file:///Users/eodemir/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///Users/eodemir/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,file:///Users/eodemir/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,file:///Users/eodemir/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,file:///Users/eodemir/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///Users/eodemir/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,file:///Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,file:///Users/eodemir/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar
2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:501] > Command to send: a
g
o6
i11
e

2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:512] > Answer received: !yro18
2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:501] > Command to send: c
o18
_1
e

2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:512] > Answer received: !ysspark.jars
2023-07-04 23:35:36,067 	 [DEBUG | clientserver.py:501] > Command to send: c
o18
_2
e

2023-07-04 23:35:36,068 	 [DEBUG | clientserver.py:512] > Answer received: !ysfile:///Users/eodemir/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar,file:///Users/eodemir/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///Users/eodemir/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,file:///Users/eodemir/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,file:///Users/eodemir/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,file:///Users/eodemir/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///Users/eodemir/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,file:///Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,file:///Users/eodemir/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,file:///Users/eodemir/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar
2023-07-04 23:35:36,068 	 [DEBUG | clientserver.py:501] > Command to send: a
e
o6
e

2023-07-04 23:35:36,068 	 [DEBUG | clientserver.py:512] > Answer received: !yi12
2023-07-04 23:35:36,068 	 [DEBUG | clientserver.py:501] > Command to send: r
u
JavaSparkContext
rj
e

2023-07-04 23:35:36,074 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.java.JavaSparkContext
2023-07-04 23:35:36,074 	 [DEBUG | clientserver.py:501] > Command to send: i
org.apache.spark.api.java.JavaSparkContext
ro0
e

2023-07-04 23:35:36,977 	 [DEBUG | clientserver.py:501] > Command to send: A
f450232a2d3ec9809c7fca2842ad5d64f417746dc509c99223a1f02aa0d97c27

2023-07-04 23:35:36,977 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,977 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o1
e

2023-07-04 23:35:36,977 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,977 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o2
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o3
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o4
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o5
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o7
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o8
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o9
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o10
e

2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,978 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o11
e

2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o12
e

2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o13
e

2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o14
e

2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o15
e

2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o6
e

2023-07-04 23:35:36,979 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:37,031 	 [DEBUG | clientserver.py:512] > Answer received: !yro19
2023-07-04 23:35:37,032 	 [DEBUG | clientserver.py:501] > Command to send: c
o19
sc
e

2023-07-04 23:35:37,032 	 [DEBUG | clientserver.py:512] > Answer received: !yro20
2023-07-04 23:35:37,032 	 [DEBUG | clientserver.py:501] > Command to send: c
o20
conf
e

2023-07-04 23:35:37,036 	 [DEBUG | clientserver.py:512] > Answer received: !yro21
2023-07-04 23:35:37,039 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonAccumulatorV2
rj
e

2023-07-04 23:35:37,040 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonAccumulatorV2
2023-07-04 23:35:37,040 	 [DEBUG | clientserver.py:501] > Command to send: i
org.apache.spark.api.python.PythonAccumulatorV2
s127.0.0.1
i52468
sf450232a2d3ec9809c7fca2842ad5d64f417746dc509c99223a1f02aa0d97c27
e

2023-07-04 23:35:37,041 	 [DEBUG | clientserver.py:512] > Answer received: !yro22
2023-07-04 23:35:37,041 	 [DEBUG | clientserver.py:501] > Command to send: c
o19
sc
e

2023-07-04 23:35:37,041 	 [DEBUG | clientserver.py:512] > Answer received: !yro23
2023-07-04 23:35:37,041 	 [DEBUG | clientserver.py:501] > Command to send: c
o23
register
ro22
e

2023-07-04 23:35:37,042 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:37,042 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:37,042 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:37,042 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
e

2023-07-04 23:35:37,042 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,042 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
ro19
e

2023-07-04 23:35:37,043 	 [DEBUG | clientserver.py:512] > Answer received: !ybfalse
2023-07-04 23:35:37,043 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:37,043 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:37,043 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
e

2023-07-04 23:35:37,043 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,043 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
ro19
e

2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:512] > Answer received: !yL15
2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
getSparkBufferSize
e

2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
getSparkBufferSize
ro19
e

2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:512] > Answer received: !yi65536
2023-07-04 23:35:37,044 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,045 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:501] > Command to send: c
o21
get
sspark.submit.pyFiles
s
e

2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:512] > Answer received: !ys/Users/eodemir/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.1.jar,/Users/eodemir/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.1.jar,/Users/eodemir/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar,/Users/eodemir/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,/Users/eodemir/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,/Users/eodemir/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,/Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,/Users/eodemir/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,/Users/eodemir/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,/Users/eodemir/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,/Users/eodemir/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,/Users/eodemir/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,/Users/eodemir/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar
2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,046 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,047 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,048 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,049 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,050 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,051 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,052 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,053 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,054 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,055 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,056 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,057 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,058 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.SparkFiles
2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/userFiles-bfb9aea5-ccd9-4cd3-9848-8fc2915daf98
2023-07-04 23:35:37,059 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.util
rj
e

2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,060 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.util.Utils
rj
e

2023-07-04 23:35:37,061 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.util.Utils
2023-07-04 23:35:37,061 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.util.Utils
getLocalDir
e

2023-07-04 23:35:37,062 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,062 	 [DEBUG | clientserver.py:501] > Command to send: c
o19
sc
e

2023-07-04 23:35:37,062 	 [DEBUG | clientserver.py:512] > Answer received: !yro24
2023-07-04 23:35:37,062 	 [DEBUG | clientserver.py:501] > Command to send: c
o24
conf
e

2023-07-04 23:35:37,062 	 [DEBUG | clientserver.py:512] > Answer received: !yro25
2023-07-04 23:35:37,062 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.util.Utils
getLocalDir
ro25
e

2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03
2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.util
rj
e

2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.util.Utils
rj
e

2023-07-04 23:35:37,063 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.util.Utils
2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.util.Utils
createTempDir
e

2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.util.Utils
createTempDir
s/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03
spyspark
e

2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:512] > Answer received: !yro26
2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:501] > Command to send: c
o26
getAbsolutePath
e

2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:512] > Answer received: !ys/private/var/folders/6d/b6j5vvg57zv35mjvq79s_s700000gn/T/spark-214fffee-3257-4dbf-8b88-41fdb667ae03/pyspark-332053ef-b4d1-4ce7-8260-5aca20b85208
2023-07-04 23:35:37,064 	 [DEBUG | clientserver.py:501] > Command to send: c
o21
get
sspark.python.profile
sfalse
e

2023-07-04 23:35:37,065 	 [DEBUG | clientserver.py:512] > Answer received: !ysfalse
2023-07-04 23:35:37,065 	 [DEBUG | clientserver.py:501] > Command to send: r
u
SparkSession
rj
e

2023-07-04 23:35:37,075 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.SparkSession
2023-07-04 23:35:37,075 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.SparkSession
getDefaultSession
e

2023-07-04 23:35:37,087 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,087 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.SparkSession
getDefaultSession
e

2023-07-04 23:35:37,087 	 [DEBUG | clientserver.py:512] > Answer received: !yro27
2023-07-04 23:35:37,087 	 [DEBUG | clientserver.py:501] > Command to send: c
o27
isDefined
e

2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:512] > Answer received: !ybfalse
2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:501] > Command to send: r
u
SparkSession
rj
e

2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.SparkSession
2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:501] > Command to send: c
o19
sc
e

2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:512] > Answer received: !yro28
2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.HashMap
e

2023-07-04 23:35:37,088 	 [DEBUG | clientserver.py:512] > Answer received: !yao29
2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:501] > Command to send: c
o29
put
sspark.app.name
sSpark Kafka Streaming
e

2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:512] > Answer received: !yn
2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:501] > Command to send: c
o29
put
sspark.master
slocal[1]
e

2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:512] > Answer received: !yn
2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:501] > Command to send: c
o29
put
sspark.jars.packages
sorg.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1
e

2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:512] > Answer received: !yn
2023-07-04 23:35:37,089 	 [DEBUG | clientserver.py:501] > Command to send: i
org.apache.spark.sql.SparkSession
ro28
ro29
e

2023-07-04 23:35:37,109 	 [DEBUG | clientserver.py:512] > Answer received: !yro30
2023-07-04 23:35:37,109 	 [DEBUG | clientserver.py:501] > Command to send: r
u
SparkSession
rj
e

2023-07-04 23:35:37,109 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.SparkSession
2023-07-04 23:35:37,109 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.SparkSession
setDefaultSession
e

2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.SparkSession
setDefaultSession
ro30
e

2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:501] > Command to send: r
u
SparkSession
rj
e

2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.SparkSession
2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro30
e

2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:37,110 	 [INFO | spark_stream_table1.py:84] > Successfully created object of SparkPipeline class.
2023-07-04 23:35:37,110 	 [DEBUG | clientserver.py:501] > Command to send: c
o30
read
e

2023-07-04 23:35:37,351 	 [DEBUG | clientserver.py:512] > Answer received: !yro31
2023-07-04 23:35:37,351 	 [DEBUG | clientserver.py:501] > Command to send: c
o31
format
scsv
e

2023-07-04 23:35:37,355 	 [DEBUG | clientserver.py:512] > Answer received: !yro32
2023-07-04 23:35:37,355 	 [DEBUG | clientserver.py:501] > Command to send: c
o32
option
sheader
strue
e

2023-07-04 23:35:37,355 	 [DEBUG | clientserver.py:512] > Answer received: !yro33
2023-07-04 23:35:37,356 	 [DEBUG | clientserver.py:501] > Command to send: c
o33
option
sdelimiter
s,
e

2023-07-04 23:35:37,356 	 [DEBUG | clientserver.py:512] > Answer received: !yro34
2023-07-04 23:35:37,356 	 [DEBUG | clientserver.py:501] > Command to send: c
o34
load
s./data_simulation/sample_data/customer.csv
e

2023-07-04 23:35:37,984 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o29
e

2023-07-04 23:35:37,985 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:512] > Answer received: !yro35
2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:501] > Command to send: c
o30
read
e

2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:512] > Answer received: !yro36
2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:501] > Command to send: c
o36
format
scsv
e

2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:512] > Answer received: !yro37
2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:501] > Command to send: c
o37
option
sheader
strue
e

2023-07-04 23:35:38,865 	 [DEBUG | clientserver.py:512] > Answer received: !yro38
2023-07-04 23:35:38,866 	 [DEBUG | clientserver.py:501] > Command to send: c
o38
option
sdelimiter
s,
e

2023-07-04 23:35:38,866 	 [DEBUG | clientserver.py:512] > Answer received: !yro39
2023-07-04 23:35:38,866 	 [DEBUG | clientserver.py:501] > Command to send: c
o39
load
s./data_simulation/sample_data/exchange_rate.csv
e

2023-07-04 23:35:38,983 	 [DEBUG | clientserver.py:512] > Answer received: !yro40
2023-07-04 23:35:38,983 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:38,983 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:38,983 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2023-07-04 23:35:38,984 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:38,984 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:38,984 	 [DEBUG | clientserver.py:512] > Answer received: !ylo41
2023-07-04 23:35:38,984 	 [DEBUG | clientserver.py:501] > Command to send: c
o41
add
scustomer_id
e

2023-07-04 23:35:38,984 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:38,984 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro41
e

2023-07-04 23:35:38,985 	 [DEBUG | clientserver.py:512] > Answer received: !yro42
2023-07-04 23:35:38,985 	 [DEBUG | clientserver.py:501] > Command to send: c
o35
dropDuplicates
ro42
e

2023-07-04 23:35:38,987 	 [DEBUG | clientserver.py:512] > Answer received: !yro43
2023-07-04 23:35:38,987 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:38,987 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:38,987 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2023-07-04 23:35:38,987 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:38,987 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:512] > Answer received: !ylo44
2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:501] > Command to send: c
o44
add
scustomer_age
e

2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:501] > Command to send: c
o44
add
scustomer_gender
e

2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro44
e

2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:512] > Answer received: !yro45
2023-07-04 23:35:38,988 	 [DEBUG | clientserver.py:501] > Command to send: c
o43
drop
ro45
e

2023-07-04 23:35:38,990 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o41
e

2023-07-04 23:35:38,990 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:38,990 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o44
e

2023-07-04 23:35:38,990 	 [DEBUG | clientserver.py:512] > Answer received: !yro46
2023-07-04 23:35:38,990 	 [DEBUG | clientserver.py:501] > Command to send: c
o40
dropDuplicates
e

2023-07-04 23:35:38,990 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:38,991 	 [DEBUG | clientserver.py:512] > Answer received: !yro47
2023-07-04 23:35:38,992 	 [DEBUG | clientserver.py:501] > Command to send: c
o47
schema
e

2023-07-04 23:35:38,992 	 [DEBUG | clientserver.py:512] > Answer received: !yro48
2023-07-04 23:35:38,992 	 [DEBUG | clientserver.py:501] > Command to send: c
o48
json
e

2023-07-04 23:35:38,998 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"exchange_rate_id","type":"string","nullable":true,"metadata":{}},{"name":"from_currency","type":"string","nullable":true,"metadata":{}},{"name":"to_currency","type":"string","nullable":true,"metadata":{}},{"name":"effective_date","type":"string","nullable":true,"metadata":{}},{"name":"rate","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:38,999 	 [DEBUG | clientserver.py:501] > Command to send: c
o47
apply
srate
e

2023-07-04 23:35:38,999 	 [DEBUG | clientserver.py:512] > Answer received: !yro49
2023-07-04 23:35:38,999 	 [DEBUG | clientserver.py:501] > Command to send: c
o49
notEqual
s1
e

2023-07-04 23:35:39,000 	 [DEBUG | clientserver.py:512] > Answer received: !yro50
2023-07-04 23:35:39,000 	 [DEBUG | clientserver.py:501] > Command to send: c
o47
filter
ro50
e

2023-07-04 23:35:39,002 	 [DEBUG | clientserver.py:512] > Answer received: !yro51
2023-07-04 23:35:39,002 	 [DEBUG | clientserver.py:501] > Command to send: c
o51
showString
i20
i20
bFalse
e

2023-07-04 23:35:39,374 	 [DEBUG | clientserver.py:512] > Answer received: !ys+----------------+-------------+-----------+--------------+----------+\n|exchange_rate_id|from_currency|to_currency|effective_date|      rate|\n+----------------+-------------+-----------+--------------+----------+\n|              80|          GBP|        USD|    2019-01-27|  1.320794|\n|            5724|          GBP|        JPY|    2019-09-03|127.978559|\n|             743|          GBP|        USD|    2019-09-05|  1.232339|\n|             776|          GBP|        USD|    2019-09-16|  1.242699|\n|             940|          GBP|        EUR|    2019-11-10|  1.160867|\n|             977|          GBP|        USD|    2019-11-22|    1.2835|\n|            6268|          GBP|        JPY|    2020-01-16|144.088697|\n|            1741|          GBP|        EUR|    2020-08-02|  1.111948|\n|            2246|          GBP|        USD|    2021-01-16|   1.35885|\n|            7900|          GBP|        JPY|    2021-02-26| 148.43979|\n|            7984|          GBP|        JPY|    2021-03-19|151.077642|\n|            8012|          GBP|        JPY|    2021-03-26|151.087035|\n|            2824|          GBP|        EUR|    2021-07-28|  1.173782|\n|            8820|          GBP|        JPY|    2021-10-14|155.621546|\n|            9816|          GBP|        JPY|    2022-06-19|165.412743|\n|            3940|          GBP|        EUR|    2022-08-03|  1.194974|\n|            4490|          GBP|        USD|    2023-02-01|  1.238659|\n|            4400|          GBP|        USD|    2023-01-02|  1.206214|\n|            5064|          GBP|        JPY|    2019-03-22|145.221964|\n|            5144|          GBP|        JPY|    2019-04-11|145.730599|\n+----------------+-------------+-----------+--------------+----------+\nonly showing top 20 rows\n
2023-07-04 23:35:39,375 	 [INFO | spark_stream_table1.py:102] > Successfully completed load_batch_data function.
2023-07-04 23:35:39,375 	 [DEBUG | clientserver.py:501] > Command to send: c
o30
readStream
e

2023-07-04 23:35:39,375 	 [DEBUG | clientserver.py:512] > Answer received: !yro52
2023-07-04 23:35:39,375 	 [DEBUG | clientserver.py:501] > Command to send: c
o52
format
skafka
e

2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:512] > Answer received: !yro53
2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:501] > Command to send: c
o53
option
skafka.bootstrap.servers
slocalhost:9092
e

2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:512] > Answer received: !yro54
2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:501] > Command to send: c
o54
option
ssubscribe
stransaction_topic
e

2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:512] > Answer received: !yro55
2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:501] > Command to send: c
o55
option
sincludeHeaders
strue
e

2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:512] > Answer received: !yro56
2023-07-04 23:35:39,376 	 [DEBUG | clientserver.py:501] > Command to send: c
o56
option
sstartingOffsets
slatest
e

2023-07-04 23:35:39,377 	 [DEBUG | clientserver.py:512] > Answer received: !yro57
2023-07-04 23:35:39,377 	 [DEBUG | clientserver.py:501] > Command to send: c
o57
load
e

2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:512] > Answer received: !yro58
2023-07-04 23:35:39,409 	 [INFO | spark_stream_table1.py:115] > Successfully completed run_stream function!
2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:39,409 	 [DEBUG | clientserver.py:512] > Answer received: !ylo59
2023-07-04 23:35:39,410 	 [DEBUG | clientserver.py:501] > Command to send: c
o59
add
sCAST(value AS STRING)
e

2023-07-04 23:35:39,410 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,410 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro59
e

2023-07-04 23:35:39,410 	 [DEBUG | clientserver.py:512] > Answer received: !yro60
2023-07-04 23:35:39,410 	 [DEBUG | clientserver.py:501] > Command to send: c
o58
selectExpr
ro60
e

2023-07-04 23:35:39,423 	 [DEBUG | clientserver.py:512] > Answer received: !yro61
2023-07-04 23:35:39,423 	 [DEBUG | clientserver.py:501] > Command to send: r
u
functions
rj
e

2023-07-04 23:35:39,425 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.functions
2023-07-04 23:35:39,425 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.functions
expr
e

2023-07-04 23:35:39,426 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,426 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.functions
expr
ssubstring(value, 2, length(value)-4)
e

2023-07-04 23:35:39,439 	 [DEBUG | clientserver.py:512] > Answer received: !yro62
2023-07-04 23:35:39,439 	 [DEBUG | clientserver.py:501] > Command to send: c
o61
withColumn
sNEW
ro62
e

2023-07-04 23:35:39,449 	 [DEBUG | clientserver.py:512] > Answer received: !yro63
2023-07-04 23:35:39,449 	 [DEBUG | clientserver.py:501] > Command to send: c
o63
apply
sNEW
e

2023-07-04 23:35:39,450 	 [DEBUG | clientserver.py:512] > Answer received: !yro64
2023-07-04 23:35:39,450 	 [DEBUG | clientserver.py:501] > Command to send: r
u
functions
rj
e

2023-07-04 23:35:39,450 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.functions
2023-07-04 23:35:39,450 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.functions
split
e

2023-07-04 23:35:39,450 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,450 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.functions
split
ro64
s,
i-1
e

2023-07-04 23:35:39,451 	 [DEBUG | clientserver.py:512] > Answer received: !yro65
2023-07-04 23:35:39,451 	 [DEBUG | clientserver.py:501] > Command to send: c
o65
apply
i0
e

2023-07-04 23:35:39,451 	 [DEBUG | clientserver.py:512] > Answer received: !yro66
2023-07-04 23:35:39,451 	 [DEBUG | clientserver.py:501] > Command to send: c
o63
withColumn
stransaction_id
ro66
e

2023-07-04 23:35:39,454 	 [DEBUG | clientserver.py:512] > Answer received: !yro67
2023-07-04 23:35:39,454 	 [DEBUG | clientserver.py:501] > Command to send: c
o65
apply
i1
e

2023-07-04 23:35:39,454 	 [DEBUG | clientserver.py:512] > Answer received: !yro68
2023-07-04 23:35:39,454 	 [DEBUG | clientserver.py:501] > Command to send: c
o67
withColumn
scustomer_id
ro68
e

2023-07-04 23:35:39,456 	 [DEBUG | clientserver.py:512] > Answer received: !yro69
2023-07-04 23:35:39,456 	 [DEBUG | clientserver.py:501] > Command to send: c
o65
apply
i2
e

2023-07-04 23:35:39,457 	 [DEBUG | clientserver.py:512] > Answer received: !yro70
2023-07-04 23:35:39,457 	 [DEBUG | clientserver.py:501] > Command to send: c
o69
withColumn
stransaction_type
ro70
e

2023-07-04 23:35:39,459 	 [DEBUG | clientserver.py:512] > Answer received: !yro71
2023-07-04 23:35:39,459 	 [DEBUG | clientserver.py:501] > Command to send: c
o65
apply
i3
e

2023-07-04 23:35:39,459 	 [DEBUG | clientserver.py:512] > Answer received: !yro72
2023-07-04 23:35:39,459 	 [DEBUG | clientserver.py:501] > Command to send: c
o72
cast
sfloat
e

2023-07-04 23:35:39,460 	 [DEBUG | clientserver.py:512] > Answer received: !yro73
2023-07-04 23:35:39,460 	 [DEBUG | clientserver.py:501] > Command to send: c
o71
withColumn
samount
ro73
e

2023-07-04 23:35:39,462 	 [DEBUG | clientserver.py:512] > Answer received: !yro74
2023-07-04 23:35:39,462 	 [DEBUG | clientserver.py:501] > Command to send: c
o65
apply
i4
e

2023-07-04 23:35:39,462 	 [DEBUG | clientserver.py:512] > Answer received: !yro75
2023-07-04 23:35:39,462 	 [DEBUG | clientserver.py:501] > Command to send: c
o74
withColumn
scurrency
ro75
e

2023-07-04 23:35:39,465 	 [DEBUG | clientserver.py:512] > Answer received: !yro76
2023-07-04 23:35:39,465 	 [DEBUG | clientserver.py:501] > Command to send: c
o65
apply
i5
e

2023-07-04 23:35:39,465 	 [DEBUG | clientserver.py:512] > Answer received: !yro77
2023-07-04 23:35:39,465 	 [DEBUG | clientserver.py:501] > Command to send: c
o76
withColumn
stransaction_date
ro77
e

2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:512] > Answer received: !yro78
2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:39,469 	 [DEBUG | clientserver.py:512] > Answer received: !ylo79
2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:501] > Command to send: c
o79
add
sNEW
e

2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:501] > Command to send: c
o79
add
svalue
e

2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro79
e

2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:512] > Answer received: !yro80
2023-07-04 23:35:39,470 	 [DEBUG | clientserver.py:501] > Command to send: c
o78
drop
ro80
e

2023-07-04 23:35:39,472 	 [DEBUG | clientserver.py:512] > Answer received: !yro81
2023-07-04 23:35:39,472 	 [INFO | spark_stream_table1.py:133] > Successfully completed transform_stream_data function!
2023-07-04 23:35:39,472 	 [DEBUG | clientserver.py:501] > Command to send: c
o46
schema
e

2023-07-04 23:35:39,472 	 [DEBUG | clientserver.py:512] > Answer received: !yro82
2023-07-04 23:35:39,472 	 [DEBUG | clientserver.py:501] > Command to send: c
o82
json
e

2023-07-04 23:35:39,472 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"country","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:501] > Command to send: c
o46
apply
scustomer_id
e

2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:512] > Answer received: !yro83
2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:501] > Command to send: c
o81
schema
e

2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:512] > Answer received: !yro84
2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:501] > Command to send: c
o84
json
e

2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"transaction_id","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"transaction_type","type":"string","nullable":true,"metadata":{}},{"name":"amount","type":"float","nullable":true,"metadata":{}},{"name":"currency","type":"string","nullable":true,"metadata":{}},{"name":"transaction_date","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,473 	 [DEBUG | clientserver.py:501] > Command to send: c
o81
apply
scustomer_id
e

2023-07-04 23:35:39,474 	 [DEBUG | clientserver.py:512] > Answer received: !yro85
2023-07-04 23:35:39,474 	 [DEBUG | clientserver.py:501] > Command to send: c
o83
equalTo
ro85
e

2023-07-04 23:35:39,474 	 [DEBUG | clientserver.py:512] > Answer received: !yro86
2023-07-04 23:35:39,474 	 [DEBUG | clientserver.py:501] > Command to send: c
o81
join
ro46
ro86
sinner
e

2023-07-04 23:35:39,481 	 [DEBUG | clientserver.py:512] > Answer received: !yro87
2023-07-04 23:35:39,481 	 [DEBUG | clientserver.py:501] > Command to send: c
o51
schema
e

2023-07-04 23:35:39,481 	 [DEBUG | clientserver.py:512] > Answer received: !yro88
2023-07-04 23:35:39,481 	 [DEBUG | clientserver.py:501] > Command to send: c
o88
json
e

2023-07-04 23:35:39,482 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"exchange_rate_id","type":"string","nullable":true,"metadata":{}},{"name":"from_currency","type":"string","nullable":true,"metadata":{}},{"name":"to_currency","type":"string","nullable":true,"metadata":{}},{"name":"effective_date","type":"string","nullable":true,"metadata":{}},{"name":"rate","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,482 	 [DEBUG | clientserver.py:501] > Command to send: c
o51
apply
seffective_date
e

2023-07-04 23:35:39,482 	 [DEBUG | clientserver.py:512] > Answer received: !yro89
2023-07-04 23:35:39,482 	 [DEBUG | clientserver.py:501] > Command to send: c
o87
schema
e

2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:512] > Answer received: !yro90
2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:501] > Command to send: c
o90
json
e

2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"transaction_id","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"transaction_type","type":"string","nullable":true,"metadata":{}},{"name":"amount","type":"float","nullable":true,"metadata":{}},{"name":"currency","type":"string","nullable":true,"metadata":{}},{"name":"transaction_date","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"country","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:501] > Command to send: c
o87
apply
stransaction_date
e

2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:512] > Answer received: !yro91
2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:501] > Command to send: c
o89
equalTo
ro91
e

2023-07-04 23:35:39,483 	 [DEBUG | clientserver.py:512] > Answer received: !yro92
2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:501] > Command to send: c
o51
apply
sto_currency
e

2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:512] > Answer received: !yro93
2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:501] > Command to send: c
o87
apply
scurrency
e

2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:512] > Answer received: !yro94
2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:501] > Command to send: c
o93
equalTo
ro94
e

2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:512] > Answer received: !yro95
2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:501] > Command to send: c
o92
and
ro95
e

2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:512] > Answer received: !yro96
2023-07-04 23:35:39,484 	 [DEBUG | clientserver.py:501] > Command to send: c
o87
join
ro51
ro96
sleft
e

2023-07-04 23:35:39,490 	 [DEBUG | clientserver.py:512] > Answer received: !yro97
2023-07-04 23:35:39,490 	 [DEBUG | clientserver.py:501] > Command to send: r
u
functions
rj
e

2023-07-04 23:35:39,490 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.functions
2023-07-04 23:35:39,490 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.functions
col
e

2023-07-04 23:35:39,490 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,490 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.functions
col
scurrency
e

2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:512] > Answer received: !yro98
2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:501] > Command to send: c
o98
equalTo
sGBP
e

2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:512] > Answer received: !yro99
2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:501] > Command to send: c
o97
schema
e

2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:512] > Answer received: !yro100
2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:501] > Command to send: c
o100
json
e

2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"transaction_id","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"transaction_type","type":"string","nullable":true,"metadata":{}},{"name":"amount","type":"float","nullable":true,"metadata":{}},{"name":"currency","type":"string","nullable":true,"metadata":{}},{"name":"transaction_date","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"country","type":"string","nullable":true,"metadata":{}},{"name":"exchange_rate_id","type":"string","nullable":true,"metadata":{}},{"name":"from_currency","type":"string","nullable":true,"metadata":{}},{"name":"to_currency","type":"string","nullable":true,"metadata":{}},{"name":"effective_date","type":"string","nullable":true,"metadata":{}},{"name":"rate","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,491 	 [DEBUG | clientserver.py:501] > Command to send: c
o97
apply
samount
e

2023-07-04 23:35:39,492 	 [DEBUG | clientserver.py:512] > Answer received: !yro101
2023-07-04 23:35:39,492 	 [DEBUG | clientserver.py:501] > Command to send: r
u
functions
rj
e

2023-07-04 23:35:39,492 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.functions
2023-07-04 23:35:39,492 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.functions
when
e

2023-07-04 23:35:39,492 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,492 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.functions
when
ro99
ro101
e

2023-07-04 23:35:39,493 	 [DEBUG | clientserver.py:512] > Answer received: !yro102
2023-07-04 23:35:39,493 	 [DEBUG | clientserver.py:501] > Command to send: c
o97
apply
samount
e

2023-07-04 23:35:39,493 	 [DEBUG | clientserver.py:512] > Answer received: !yro103
2023-07-04 23:35:39,493 	 [DEBUG | clientserver.py:501] > Command to send: c
o97
apply
srate
e

2023-07-04 23:35:39,493 	 [DEBUG | clientserver.py:512] > Answer received: !yro104
2023-07-04 23:35:39,493 	 [DEBUG | clientserver.py:501] > Command to send: c
o103
divide
ro104
e

2023-07-04 23:35:39,494 	 [DEBUG | clientserver.py:512] > Answer received: !yro105
2023-07-04 23:35:39,494 	 [DEBUG | clientserver.py:501] > Command to send: c
o102
otherwise
ro105
e

2023-07-04 23:35:39,494 	 [DEBUG | clientserver.py:512] > Answer received: !yro106
2023-07-04 23:35:39,494 	 [DEBUG | clientserver.py:501] > Command to send: c
o97
withColumn
sgbp_amount
ro106
e

2023-07-04 23:35:39,503 	 [DEBUG | clientserver.py:512] > Answer received: !yro107
2023-07-04 23:35:39,503 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:39,503 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:39,503 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2023-07-04 23:35:39,503 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,503 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:512] > Answer received: !ylo108
2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:501] > Command to send: c
o108
add
sexchange_rate_id
e

2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:501] > Command to send: c
o108
add
seffective_date
e

2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:501] > Command to send: c
o108
add
stransaction_type
e

2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:501] > Command to send: c
o108
add
sfrom_currency
e

2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,504 	 [DEBUG | clientserver.py:501] > Command to send: c
o108
add
sto_currency
e

2023-07-04 23:35:39,505 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,505 	 [DEBUG | clientserver.py:501] > Command to send: c
o108
add
srate
e

2023-07-04 23:35:39,505 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,505 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro108
e

2023-07-04 23:35:39,505 	 [DEBUG | clientserver.py:512] > Answer received: !yro109
2023-07-04 23:35:39,505 	 [DEBUG | clientserver.py:501] > Command to send: c
o107
drop
ro109
e

2023-07-04 23:35:39,508 	 [DEBUG | clientserver.py:512] > Answer received: !yro110
2023-07-04 23:35:39,508 	 [DEBUG | clientserver.py:501] > Command to send: c
o110
schema
e

2023-07-04 23:35:39,508 	 [DEBUG | clientserver.py:512] > Answer received: !yro111
2023-07-04 23:35:39,508 	 [DEBUG | clientserver.py:501] > Command to send: c
o111
json
e

2023-07-04 23:35:39,508 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"transaction_id","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"amount","type":"float","nullable":true,"metadata":{}},{"name":"currency","type":"string","nullable":true,"metadata":{}},{"name":"transaction_date","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"country","type":"string","nullable":true,"metadata":{}},{"name":"gbp_amount","type":"double","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,508 	 [DEBUG | clientserver.py:501] > Command to send: c
o110
apply
stransaction_date
e

2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:512] > Answer received: !yro112
2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:501] > Command to send: c
o51
apply
seffective_date
e

2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:512] > Answer received: !yro113
2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:501] > Command to send: c
o112
equalTo
ro113
e

2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:512] > Answer received: !yro114
2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:501] > Command to send: c
o51
apply
sto_currency
e

2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:512] > Answer received: !yro115
2023-07-04 23:35:39,509 	 [DEBUG | clientserver.py:501] > Command to send: c
o115
equalTo
sEUR
e

2023-07-04 23:35:39,510 	 [DEBUG | clientserver.py:512] > Answer received: !yro116
2023-07-04 23:35:39,510 	 [DEBUG | clientserver.py:501] > Command to send: c
o114
and
ro116
e

2023-07-04 23:35:39,510 	 [DEBUG | clientserver.py:512] > Answer received: !yro117
2023-07-04 23:35:39,510 	 [DEBUG | clientserver.py:501] > Command to send: c
o110
join
ro51
ro117
sinner
e

2023-07-04 23:35:39,514 	 [DEBUG | clientserver.py:512] > Answer received: !yro118
2023-07-04 23:35:39,514 	 [DEBUG | clientserver.py:501] > Command to send: r
u
functions
rj
e

2023-07-04 23:35:39,515 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.functions
2023-07-04 23:35:39,515 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.functions
col
e

2023-07-04 23:35:39,515 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,515 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.functions
col
scurrency
e

2023-07-04 23:35:39,515 	 [DEBUG | clientserver.py:512] > Answer received: !yro119
2023-07-04 23:35:39,515 	 [DEBUG | clientserver.py:501] > Command to send: c
o119
equalTo
sEUR
e

2023-07-04 23:35:39,516 	 [DEBUG | clientserver.py:512] > Answer received: !yro120
2023-07-04 23:35:39,516 	 [DEBUG | clientserver.py:501] > Command to send: c
o118
schema
e

2023-07-04 23:35:39,516 	 [DEBUG | clientserver.py:512] > Answer received: !yro121
2023-07-04 23:35:39,516 	 [DEBUG | clientserver.py:501] > Command to send: c
o121
json
e

2023-07-04 23:35:39,516 	 [DEBUG | clientserver.py:512] > Answer received: !ys{"type":"struct","fields":[{"name":"transaction_id","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"amount","type":"float","nullable":true,"metadata":{}},{"name":"currency","type":"string","nullable":true,"metadata":{}},{"name":"transaction_date","type":"string","nullable":true,"metadata":{}},{"name":"customer_id","type":"string","nullable":true,"metadata":{}},{"name":"country","type":"string","nullable":true,"metadata":{}},{"name":"gbp_amount","type":"double","nullable":true,"metadata":{}},{"name":"exchange_rate_id","type":"string","nullable":true,"metadata":{}},{"name":"from_currency","type":"string","nullable":true,"metadata":{}},{"name":"to_currency","type":"string","nullable":true,"metadata":{}},{"name":"effective_date","type":"string","nullable":true,"metadata":{}},{"name":"rate","type":"string","nullable":true,"metadata":{}}]}
2023-07-04 23:35:39,516 	 [DEBUG | clientserver.py:501] > Command to send: c
o118
apply
samount
e

2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:512] > Answer received: !yro122
2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:501] > Command to send: r
u
functions
rj
e

2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.functions
2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.sql.functions
when
e

2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.sql.functions
when
ro120
ro122
e

2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:512] > Answer received: !yro123
2023-07-04 23:35:39,517 	 [DEBUG | clientserver.py:501] > Command to send: c
o118
apply
sgbp_amount
e

2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:512] > Answer received: !yro124
2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:501] > Command to send: c
o118
apply
srate
e

2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:512] > Answer received: !yro125
2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:501] > Command to send: c
o124
multiply
ro125
e

2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:512] > Answer received: !yro126
2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:501] > Command to send: c
o123
otherwise
ro126
e

2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:512] > Answer received: !yro127
2023-07-04 23:35:39,518 	 [DEBUG | clientserver.py:501] > Command to send: c
o118
withColumn
seur_amount
ro127
e

2023-07-04 23:35:39,524 	 [DEBUG | clientserver.py:512] > Answer received: !yro128
2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:512] > Answer received: !ylo129
2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
sfrom_currency
e

2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,525 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
sto_currency
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
sexchange_rate_id
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
seffective_date
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
srate
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
samount
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
scurrency
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
o129
add
sgbp_amount
e

2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,526 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro129
e

2023-07-04 23:35:39,527 	 [DEBUG | clientserver.py:512] > Answer received: !yro130
2023-07-04 23:35:39,527 	 [DEBUG | clientserver.py:501] > Command to send: c
o128
drop
ro130
e

2023-07-04 23:35:39,533 	 [DEBUG | clientserver.py:512] > Answer received: !yro131
2023-07-04 23:35:39,533 	 [INFO | spark_stream_table1.py:157] > Successfully completed join_data function!
2023-07-04 23:35:39,533 	 [DEBUG | clientserver.py:501] > Command to send: c
o131
writeStream
e

2023-07-04 23:35:39,536 	 [DEBUG | clientserver.py:512] > Answer received: !yro132
2023-07-04 23:35:39,536 	 [DEBUG | clientserver.py:501] > Command to send: c
o132
format
sappend
e

2023-07-04 23:35:39,537 	 [DEBUG | clientserver.py:512] > Answer received: !yro133
2023-07-04 23:35:39,538 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonUtils
rj
e

2023-07-04 23:35:39,538 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonUtils
2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:501] > Command to send: r
m
org.apache.spark.api.python.PythonUtils
getBroadcastThreshold
e

2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:512] > Answer received: !ym
2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:501] > Command to send: c
z:org.apache.spark.api.python.PythonUtils
getBroadcastThreshold
ro19
e

2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:512] > Answer received: !yL1048576
2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:501] > Command to send: r
u
PythonFunction
rj
e

2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.api.python.PythonFunction
2023-07-04 23:35:39,539 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.HashMap
e

2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:512] > Answer received: !yao134
2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:501] > Command to send: c
o134
put
sPYTHONHASHSEED
s0
e

2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:512] > Answer received: !yn
2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:512] > Answer received: !ylo135
2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.spark_spark-sql-kafka-0-10_2.12-3.2.1.jar
e

2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.1.jar
e

2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,540 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.kafka_kafka-clients-2.8.0.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
scom.google.code.findbugs_jsr305-3.0.0.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.commons_commons-pool2-2.6.2.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.spark-project.spark_unused-1.0.0.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.hadoop_hadoop-client-runtime-3.3.1.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.lz4_lz4-java-1.7.1.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.xerial.snappy_snappy-java-1.1.8.4.jar
e

2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,541 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.slf4j_slf4j-api-1.7.30.jar
e

2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.hadoop_hadoop-client-api-3.3.1.jar
e

2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
sorg.apache.htrace_htrace-core4-4.1.0-incubating.jar
e

2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:501] > Command to send: c
o135
add
scommons-logging_commons-logging-1.1.3.jar
e

2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:512] > Answer received: !ybtrue
2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:501] > Command to send: i
java.util.ArrayList
e

2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:512] > Answer received: !ylo136
2023-07-04 23:35:39,542 	 [DEBUG | clientserver.py:501] > Command to send: i
org.apache.spark.api.python.PythonFunction
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
ro134
ro135
spython3
s3.9
ro136
ro22
e

2023-07-04 23:35:39,543 	 [DEBUG | clientserver.py:512] > Answer received: !yro137
2023-07-04 23:35:39,543 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org
rj
e

2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache
rj
e

2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark
rj
e

2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.sql
rj
e

2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:39,544 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.sql.execution
rj
e

2023-07-04 23:35:39,545 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:39,545 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.sql.execution.python
rj
e

2023-07-04 23:35:39,545 	 [DEBUG | clientserver.py:512] > Answer received: !yp
2023-07-04 23:35:39,545 	 [DEBUG | clientserver.py:501] > Command to send: r
u
org.apache.spark.sql.execution.python.PythonForeachWriter
rj
e

2023-07-04 23:35:39,545 	 [DEBUG | clientserver.py:512] > Answer received: !ycorg.apache.spark.sql.execution.python.PythonForeachWriter
2023-07-04 23:35:39,545 	 [DEBUG | clientserver.py:501] > Command to send: c
o131
schema
e

2023-07-04 23:35:39,546 	 [DEBUG | clientserver.py:512] > Answer received: !yro138
2023-07-04 23:35:39,546 	 [DEBUG | clientserver.py:501] > Command to send: i
org.apache.spark.sql.execution.python.PythonForeachWriter
ro137
ro138
e

2023-07-04 23:35:39,546 	 [DEBUG | clientserver.py:512] > Answer received: !yro139
2023-07-04 23:35:39,546 	 [DEBUG | clientserver.py:501] > Command to send: c
o133
foreach
ro139
e

2023-07-04 23:35:39,546 	 [DEBUG | clientserver.py:512] > Answer received: !yro140
2023-07-04 23:35:39,546 	 [DEBUG | clientserver.py:501] > Command to send: c
o133
start
e

2023-07-04 23:35:39,666 	 [DEBUG | clientserver.py:512] > Answer received: !yro141
2023-07-04 23:35:39,666 	 [DEBUG | clientserver.py:501] > Command to send: c
o141
awaitTermination
e

2023-07-04 23:35:39,995 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o59
e

2023-07-04 23:35:39,995 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o17
e

2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o18
e

2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o20
e

2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o23
e

2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o24
e

2023-07-04 23:35:39,996 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,997 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o25
e

2023-07-04 23:35:39,997 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,997 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o26
e

2023-07-04 23:35:39,997 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o27
e

2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o28
e

2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o31
e

2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o32
e

2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o33
e

2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o34
e

2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,998 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o35
e

2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o36
e

2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o37
e

2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o38
e

2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o39
e

2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o40
e

2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:39,999 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o42
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o43
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o45
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o47
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o48
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o49
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o50
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o52
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o53
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o54
e

2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,000 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o55
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o56
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o57
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o58
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o60
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o61
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o62
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o64
e

2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,001 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o66
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o67
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o68
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o69
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o70
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o72
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o79
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o108
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o129
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o74
e

2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,002 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o75
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o76
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o77
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o78
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o80
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o82
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o83
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o84
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o85
e

2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,003 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o86
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o88
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o89
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o90
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o91
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o92
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o93
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o94
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o95
e

2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,004 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o96
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o97
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o98
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o99
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o100
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o101
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o102
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o103
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o104
e

2023-07-04 23:35:40,005 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o105
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o106
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o107
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o109
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o110
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o111
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o112
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o113
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o114
e

2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,006 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o115
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o116
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o117
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o118
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o119
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o120
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o121
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o122
e

2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,007 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o123
e

2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o124
e

2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o125
e

2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o126
e

2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,008 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o127
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o128
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o130
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o132
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o134
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o135
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o136
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:501] > Command to send: m
d
o140
e

2023-07-04 23:35:40,009 	 [DEBUG | clientserver.py:512] > Answer received: !yv
2023-07-04 23:35:40,806 	 [INFO | tools.py:31] > .
2023-07-04 23:35:40,807 	 [INFO | tools.py:32] > ..
2023-07-04 23:35:40,807 	 [INFO | tools.py:33] > Repo is starting...
2023-07-04 23:35:40,807 	 [INFO | tools.py:34] > Configuration file is read successfully.
2023-07-04 23:35:40,807 	 [INFO | tools.py:45] > Adjusted KafkaConnection in order to move the data.
2023-07-04 23:35:40,807 	 [DEBUG | kafka.py:347] > Starting the Kafka producer
2023-07-04 23:35:40,807 	 [ERROR | transaction_producer.py:35] > Error __init__: Unrecognized configs: {'bootstrap_sesrvers': 'localhost:9092'}
Traceback (most recent call last):
  File "/Users/eodemir/Documents/GitHub/Friendsurance_senior_data_engineer_challenge/data_simulation/src/transaction_producer.py", line 30, in __init__
    self.main_producer = KafkaProducer(bootstrap_sesrvers=BOOTSTRAP_SERVERS,
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/kafka/producer/kafka.py", line 354, in __init__
    assert not configs, 'Unrecognized configs: %s' % (configs,)
AssertionError: Unrecognized configs: {'bootstrap_sesrvers': 'localhost:9092'}
2023-07-04 23:35:46,511 	 [INFO | tools.py:31] > .
2023-07-04 23:35:46,511 	 [INFO | tools.py:32] > ..
2023-07-04 23:35:46,512 	 [INFO | tools.py:33] > Repo is starting...
2023-07-04 23:35:46,512 	 [INFO | tools.py:34] > Configuration file is read successfully.
2023-07-04 23:35:46,512 	 [INFO | tools.py:45] > Adjusted KafkaConnection in order to move the data.
2023-07-04 23:35:46,512 	 [DEBUG | kafka.py:347] > Starting the Kafka producer
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name connections-closed
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name connections-created
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name select-time
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name io-time
2023-07-04 23:35:46,512 	 [DEBUG | client_async.py:374] > Initiating connection to node bootstrap-0 at localhost:9092
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name bytes-sent-received
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name bytes-sent
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name bytes-received
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name request-latency
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name node-bootstrap-0.bytes-sent
2023-07-04 23:35:46,512 	 [DEBUG | metrics.py:156] > Added sensor with name node-bootstrap-0.bytes-received
2023-07-04 23:35:46,513 	 [DEBUG | metrics.py:156] > Added sensor with name node-bootstrap-0.latency
2023-07-04 23:35:46,521 	 [DEBUG | conn.py:368] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <disconnected> [unspecified None]>: creating new socket
2023-07-04 23:35:46,522 	 [DEBUG | conn.py:374] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <disconnected> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2023-07-04 23:35:46,522 	 [INFO | conn.py:380] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-07-04 23:35:46,522 	 [INFO | conn.py:1205] > Probing node bootstrap-0 broker version
2023-07-04 23:35:46,523 	 [DEBUG | conn.py:394] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2023-07-04 23:35:46,523 	 [INFO | conn.py:410] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-07-04 23:35:46,523 	 [DEBUG | client_async.py:283] > Node bootstrap-0 connected
2023-07-04 23:35:46,523 	 [DEBUG | parser.py:59] > Sending request ApiVersionRequest_v0()
2023-07-04 23:35:46,523 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 1: ApiVersionRequest_v0()
2023-07-04 23:35:46,625 	 [DEBUG | parser.py:59] > Sending request MetadataRequest_v0(topics=[])
2023-07-04 23:35:46,625 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 2: MetadataRequest_v0(topics=[])
2023-07-04 23:35:46,625 	 [DEBUG | parser.py:139] > Received correlation id: 1
2023-07-04 23:35:46,625 	 [DEBUG | parser.py:166] > Processing response ApiVersionResponse_v0
2023-07-04 23:35:46,626 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 1 (102.08296775817871 ms): ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=9), (api_key=1, min_version=0, max_version=12), (api_key=2, min_version=0, max_version=7), (api_key=3, min_version=0, max_version=11), (api_key=4, min_version=0, max_version=5), (api_key=5, min_version=0, max_version=3), (api_key=6, min_version=0, max_version=7), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=8), (api_key=9, min_version=0, max_version=8), (api_key=10, min_version=0, max_version=4), (api_key=11, min_version=0, max_version=7), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=4), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=4), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=4), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=3), (api_key=25, min_version=0, max_version=3), (api_key=26, min_version=0, max_version=3), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=3), (api_key=29, min_version=0, max_version=2), (api_key=30, min_version=0, max_version=2), (api_key=31, min_version=0, max_version=2), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=2), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=2), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=2), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=0), (api_key=57, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=0), (api_key=61, min_version=0, max_version=0), (api_key=65, min_version=0, max_version=0), (api_key=66, min_version=0, max_version=0), (api_key=67, min_version=0, max_version=0)])
2023-07-04 23:35:46,628 	 [DEBUG | parser.py:139] > Received correlation id: 2
2023-07-04 23:35:46,628 	 [DEBUG | parser.py:166] > Processing response MetadataResponse_v0
2023-07-04 23:35:46,629 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 2 (3.450155258178711 ms): MetadataResponse_v0(brokers=[(node_id=1001, host='localhost', port=9092)], topics=[(error_code=0, topic='transaction_topic', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='test_topic2', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='__consumer_offsets', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=10, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=20, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=40, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=30, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=9, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=39, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=11, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=31, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=13, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=18, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=22, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=8, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=32, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=43, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=29, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=34, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=1, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=6, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=41, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=27, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=48, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=5, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=15, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=35, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=25, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=46, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=26, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=36, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=44, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=16, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=37, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=17, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=45, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=3, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=4, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=24, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=38, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=33, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=23, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=28, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=2, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=12, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=19, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=14, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=47, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=49, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=42, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=7, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=21, leader=1001, replicas=[1001], isr=[1001])])])
2023-07-04 23:35:46,629 	 [INFO | conn.py:1267] > Broker version identified as 2.5.0
2023-07-04 23:35:46,629 	 [INFO | conn.py:1268] > Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-07-04 23:35:46,629 	 [DEBUG | metrics.py:156] > Added sensor with name bufferpool-wait-time
2023-07-04 23:35:46,629 	 [DEBUG | metrics.py:156] > Added sensor with name batch-size
2023-07-04 23:35:46,629 	 [DEBUG | metrics.py:156] > Added sensor with name compression-rate
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name queue-time
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name produce-throttle-time
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name records-per-request
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name bytes
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name record-retries
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name errors
2023-07-04 23:35:46,630 	 [DEBUG | metrics.py:156] > Added sensor with name record-size-max
2023-07-04 23:35:46,630 	 [DEBUG | sender.py:55] > Starting Kafka producer I/O thread.
2023-07-04 23:35:46,630 	 [DEBUG | kafka.py:418] > Kafka producer started
2023-07-04 23:35:46,630 	 [DEBUG | client_async.py:837] > Sending metadata request MetadataRequest_v1(topics=NULL) to node bootstrap-0
2023-07-04 23:35:46,630 	 [INFO | transaction_producer.py:33] > Successfully initialized __init__ in SimulationKafkaProducer class!
2023-07-04 23:35:46,630 	 [DEBUG | parser.py:59] > Sending request MetadataRequest_v1(topics=NULL)
2023-07-04 23:35:46,630 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 3: MetadataRequest_v1(topics=NULL)
2023-07-04 23:35:46,633 	 [DEBUG | kafka.py:693] > Requesting metadata update for topic transaction_topic
2023-07-04 23:35:46,633 	 [DEBUG | parser.py:139] > Received correlation id: 3
2023-07-04 23:35:46,633 	 [DEBUG | parser.py:166] > Processing response MetadataResponse_v1
2023-07-04 23:35:46,634 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 3 (3.6232471466064453 ms): MetadataResponse_v1(brokers=[(node_id=1001, host='localhost', port=9092, rack=None)], controller_id=1001, topics=[(error_code=0, topic='transaction_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='test_topic2', is_internal=False, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='__consumer_offsets', is_internal=True, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=10, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=20, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=40, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=30, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=9, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=39, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=11, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=31, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=13, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=18, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=22, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=8, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=32, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=43, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=29, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=34, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=1, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=6, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=41, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=27, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=48, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=5, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=15, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=35, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=25, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=46, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=26, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=36, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=44, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=16, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=37, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=17, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=45, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=3, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=4, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=24, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=38, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=33, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=23, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=28, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=2, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=12, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=19, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=14, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=47, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=49, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=42, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=7, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=21, leader=1001, replicas=[1001], isr=[1001])])])
2023-07-04 23:35:46,634 	 [DEBUG | cluster.py:325] > Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 3, groups: 0)
2023-07-04 23:35:46,634 	 [DEBUG | kafka.py:707] > _wait_on_metadata woke after 0.0012788772583007812 secs.
2023-07-04 23:35:46,635 	 [DEBUG | kafka.py:599] > Sending (key=None value='transaction_id,customer_id,transaction_type,amount,currency,transaction_date\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:46,635 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:46,635 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:35:46,635 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:35:46,635 	 [DEBUG | sender.py:109] > Node 1001 not ready; delaying produce of accumulated batch
2023-07-04 23:35:46,635 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:46,635 	 [DEBUG | client_async.py:374] > Initiating connection to node 1001 at localhost:9092
2023-07-04 23:35:46,635 	 [DEBUG | metrics.py:156] > Added sensor with name node-1001.bytes-sent
2023-07-04 23:35:46,635 	 [DEBUG | metrics.py:156] > Added sensor with name node-1001.bytes-received
2023-07-04 23:35:46,636 	 [DEBUG | metrics.py:156] > Added sensor with name node-1001.latency
2023-07-04 23:35:46,636 	 [DEBUG | conn.py:368] > <BrokerConnection node_id=1001 host=localhost:9092 <disconnected> [unspecified None]>: creating new socket
2023-07-04 23:35:46,636 	 [DEBUG | conn.py:374] > <BrokerConnection node_id=1001 host=localhost:9092 <disconnected> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2023-07-04 23:35:46,636 	 [INFO | conn.py:380] > <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-07-04 23:35:46,636 	 [DEBUG | sender.py:109] > Node 1001 not ready; delaying produce of accumulated batch
2023-07-04 23:35:46,636 	 [DEBUG | conn.py:394] > <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2023-07-04 23:35:46,636 	 [INFO | conn.py:410] > <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-07-04 23:35:46,636 	 [DEBUG | client_async.py:283] > Node 1001 connected
2023-07-04 23:35:46,636 	 [INFO | conn.py:919] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-07-04 23:35:46,637 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.records-per-batch
2023-07-04 23:35:46,637 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.bytes
2023-07-04 23:35:46,637 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.compression-rate
2023-07-04 23:35:46,637 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.record-retries
2023-07-04 23:35:46,637 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.record-errors
2023-07-04 23:35:46,637 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:35:46,637 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02\xd3\xec\xecu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eKK\x00\x00\x01\x89"\x9eKK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])}
2023-07-04 23:35:46,637 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02\xd3\xec\xecu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eKK\x00\x00\x01\x89"\x9eKK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])
2023-07-04 23:35:46,637 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02\xd3\xec\xecu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eKK\x00\x00\x01\x89"\x9eKK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])
2023-07-04 23:35:46,637 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 1: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02\xd3\xec\xecu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eKK\x00\x00\x01\x89"\x9eKK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])
2023-07-04 23:35:46,653 	 [DEBUG | parser.py:139] > Received correlation id: 1
2023-07-04 23:35:46,653 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:35:46,653 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 1 (15.72108268737793 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=97, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:46,653 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=97, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:46,653 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 97 log start offset 0 and error None.
2023-07-04 23:35:46,653 	 [INFO | transaction_producer.py:39] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:35:46,736 	 [DEBUG | client_async.py:837] > Sending metadata request MetadataRequest_v1(topics=['transaction_topic']) to node 1001
2023-07-04 23:35:46,736 	 [DEBUG | parser.py:59] > Sending request MetadataRequest_v1(topics=['transaction_topic'])
2023-07-04 23:35:46,736 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 2: MetadataRequest_v1(topics=['transaction_topic'])
2023-07-04 23:35:46,747 	 [DEBUG | parser.py:139] > Received correlation id: 2
2023-07-04 23:35:46,747 	 [DEBUG | parser.py:166] > Processing response MetadataResponse_v1
2023-07-04 23:35:46,748 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 2 (11.000871658325195 ms): MetadataResponse_v1(brokers=[(node_id=1001, host='localhost', port=9092, rack=None)], controller_id=1001, topics=[(error_code=0, topic='transaction_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])])])
2023-07-04 23:35:46,748 	 [DEBUG | cluster.py:325] > Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, groups: 0)
2023-07-04 23:35:47,661 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000001,2506,in,509.89,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:47,661 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:47,662 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:35:47,662 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:35:47,662 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:47,662 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:35:47,662 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\x92\xc5\x81&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eOM\x00\x00\x01\x89"\x9eOM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])}
2023-07-04 23:35:47,663 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\x92\xc5\x81&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eOM\x00\x00\x01\x89"\x9eOM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])
2023-07-04 23:35:47,663 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\x92\xc5\x81&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eOM\x00\x00\x01\x89"\x9eOM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])
2023-07-04 23:35:47,663 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 3: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\x92\xc5\x81&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eOM\x00\x00\x01\x89"\x9eOM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])
2023-07-04 23:35:47,677 	 [DEBUG | parser.py:139] > Received correlation id: 3
2023-07-04 23:35:47,678 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:35:47,678 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 3 (14.289140701293945 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=98, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:47,678 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=98, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:47,678 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 98 log start offset 0 and error None.
2023-07-04 23:35:47,678 	 [INFO | transaction_producer.py:39] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:35:48,679 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000003,2373,out,248.63,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:48,680 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:48,680 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:35:48,680 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:35:48,680 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:48,681 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:35:48,681 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02tPZ\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eSH\x00\x00\x01\x89"\x9eSH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])}
2023-07-04 23:35:48,681 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02tPZ\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eSH\x00\x00\x01\x89"\x9eSH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])
2023-07-04 23:35:48,681 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02tPZ\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eSH\x00\x00\x01\x89"\x9eSH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])
2023-07-04 23:35:48,681 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 4: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02tPZ\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eSH\x00\x00\x01\x89"\x9eSH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])
2023-07-04 23:35:48,695 	 [DEBUG | parser.py:139] > Received correlation id: 4
2023-07-04 23:35:48,695 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:35:48,695 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 4 (14.268875122070312 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=99, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:48,695 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=99, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:48,696 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 99 log start offset 0 and error None.
2023-07-04 23:35:48,696 	 [INFO | transaction_producer.py:39] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:35:49,698 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000004,1289,in,478.25,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:49,698 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:49,698 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:35:49,698 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:35:49,698 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:49,699 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:35:49,699 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\xf0\xe2O\xfa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eWB\x00\x00\x01\x89"\x9eWB\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000004,1289,in,478.25,EUR,2022-...')])])}
2023-07-04 23:35:49,699 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\xf0\xe2O\xfa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eWB\x00\x00\x01\x89"\x9eWB\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000004,1289,in,478.25,EUR,2022-...')])])
2023-07-04 23:35:49,699 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\xf0\xe2O\xfa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eWB\x00\x00\x01\x89"\x9eWB\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000004,1289,in,478.25,EUR,2022-...')])])
2023-07-04 23:35:49,699 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 5: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02\xf0\xe2O\xfa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9eWB\x00\x00\x01\x89"\x9eWB\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000004,1289,in,478.25,EUR,2022-...')])])
2023-07-04 23:35:49,704 	 [DEBUG | parser.py:139] > Received correlation id: 5
2023-07-04 23:35:49,704 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:35:49,704 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 5 (5.489826202392578 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=100, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:49,705 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=100, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:49,705 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 100 log start offset 0 and error None.
2023-07-04 23:35:49,705 	 [INFO | transaction_producer.py:39] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:35:50,708 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000005,661,out,347.87,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:50,708 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:50,709 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:35:50,709 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:35:50,709 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:50,709 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:35:50,709 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02k\x0e\xf4\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e[4\x00\x00\x01\x89"\x9e[4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000005,661,out,347.87,EUR,2022-...')])])}
2023-07-04 23:35:50,709 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02k\x0e\xf4\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e[4\x00\x00\x01\x89"\x9e[4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000005,661,out,347.87,EUR,2022-...')])])
2023-07-04 23:35:50,709 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02k\x0e\xf4\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e[4\x00\x00\x01\x89"\x9e[4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000005,661,out,347.87,EUR,2022-...')])])
2023-07-04 23:35:50,709 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 6: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02k\x0e\xf4\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e[4\x00\x00\x01\x89"\x9e[4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000005,661,out,347.87,EUR,2022-...')])])
2023-07-04 23:35:50,718 	 [DEBUG | parser.py:139] > Received correlation id: 6
2023-07-04 23:35:50,718 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:35:50,718 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 6 (8.738040924072266 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=101, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:50,718 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=101, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:50,718 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 101 log start offset 0 and error None.
2023-07-04 23:35:50,718 	 [INFO | transaction_producer.py:39] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:35:51,724 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000010,1228,out,394.85,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:51,724 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:51,724 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:35:51,724 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:35:51,724 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:35:51,724 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:35:51,724 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02\xab\x92\x14|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e_,\x00\x00\x01\x89"\x9e_,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000010,1228,out,394.85,EUR,2022...')])])}
2023-07-04 23:35:51,725 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02\xab\x92\x14|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e_,\x00\x00\x01\x89"\x9e_,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000010,1228,out,394.85,EUR,2022...')])])
2023-07-04 23:35:51,725 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02\xab\x92\x14|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e_,\x00\x00\x01\x89"\x9e_,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000010,1228,out,394.85,EUR,2022...')])])
2023-07-04 23:35:51,725 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 7: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02\xab\x92\x14|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\x9e_,\x00\x00\x01\x89"\x9e_,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000010,1228,out,394.85,EUR,2022...')])])
2023-07-04 23:35:51,730 	 [DEBUG | parser.py:139] > Received correlation id: 7
2023-07-04 23:35:51,730 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:35:51,730 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 7 (5.092144012451172 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=102, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:51,730 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=102, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:35:51,730 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 102 log start offset 0 and error None.
2023-07-04 23:35:51,730 	 [INFO | transaction_producer.py:39] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:35:51,983 	 [INFO | kafka.py:483] > Closing the Kafka producer with 0 secs timeout.
2023-07-04 23:35:51,983 	 [INFO | kafka.py:499] > Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2023-07-04 23:35:51,983 	 [DEBUG | kafka.py:514] > The Kafka producer has closed.
2023-07-04 23:35:54,853 	 [DEBUG | clientserver.py:501] > Command to send: c
o19
sc
e

2023-07-04 23:35:54,854 	 [INFO | clientserver.py:538] > Error while receiving.
Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=6>
2023-07-04 23:35:54,856 	 [INFO | clientserver.py:543] > Closing down clientserver connection
2023-07-04 23:35:54,857 	 [DEBUG | java_gateway.py:490] > Exception while closing
Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=6>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 488, in quiet_close
    closable.close()
RuntimeError: reentrant call inside <_io.BufferedReader name=6>
2023-07-04 23:35:54,858 	 [ERROR | java_gateway.py:1055] > Exception while sending command.
Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=6>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-07-04 23:35:54,859 	 [INFO | clientserver.py:538] > Error while receiving.
Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/context.py", line 362, in signal_handler
    self.cancelAllJobs()
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/context.py", line 1447, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o19.sc
2023-07-04 23:35:54,862 	 [INFO | clientserver.py:543] > Closing down clientserver connection
2023-07-04 23:35:54,862 	 [ERROR | java_gateway.py:1055] > Exception while sending command.
Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/context.py", line 362, in signal_handler
    self.cancelAllJobs()
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/context.py", line 1447, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o19.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-07-04 23:35:54,862 	 [INFO | clientserver.py:543] > Closing down clientserver connection
2023-07-04 23:35:54,862 	 [ERROR | spark_stream_table1.py:166] > An error occured while initializing complete function.
Traceback (most recent call last):
  File "/Users/eodemir/Documents/GitHub/Friendsurance_senior_data_engineer_challenge/src/spark_stream_table1.py", line 164, in complete
    self.df_all.writeStream.format("append").foreach(write_to_mysql).start().awaitTermination()
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/streaming.py", line 107, in awaitTermination
    return self._jsq.awaitTermination()
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/Users/eodemir/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o141.awaitTermination
2023-07-04 23:35:54,864 	 [INFO | clientserver.py:543] > Closing down clientserver connection
2023-07-04 23:49:03,801 	 [INFO | tools.py:31] > .
2023-07-04 23:49:03,801 	 [INFO | tools.py:32] > ..
2023-07-04 23:49:03,801 	 [INFO | tools.py:33] > Repo is starting...
2023-07-04 23:49:03,801 	 [INFO | tools.py:34] > Configuration file is read successfully.
2023-07-04 23:49:03,801 	 [INFO | tools.py:45] > Adjusted KafkaConnection in order to move the data.
2023-07-04 23:49:03,801 	 [DEBUG | kafka.py:347] > Starting the Kafka producer
2023-07-04 23:49:03,801 	 [DEBUG | metrics.py:156] > Added sensor with name connections-closed
2023-07-04 23:49:03,801 	 [DEBUG | metrics.py:156] > Added sensor with name connections-created
2023-07-04 23:49:03,801 	 [DEBUG | metrics.py:156] > Added sensor with name select-time
2023-07-04 23:49:03,801 	 [DEBUG | metrics.py:156] > Added sensor with name io-time
2023-07-04 23:49:03,801 	 [DEBUG | client_async.py:374] > Initiating connection to node bootstrap-0 at localhost:9092
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name bytes-sent-received
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name bytes-sent
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name bytes-received
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name request-latency
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name node-bootstrap-0.bytes-sent
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name node-bootstrap-0.bytes-received
2023-07-04 23:49:03,802 	 [DEBUG | metrics.py:156] > Added sensor with name node-bootstrap-0.latency
2023-07-04 23:49:03,807 	 [DEBUG | conn.py:368] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <disconnected> [unspecified None]>: creating new socket
2023-07-04 23:49:03,807 	 [DEBUG | conn.py:374] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <disconnected> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2023-07-04 23:49:03,807 	 [INFO | conn.py:380] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-07-04 23:49:03,807 	 [INFO | conn.py:1205] > Probing node bootstrap-0 broker version
2023-07-04 23:49:03,808 	 [DEBUG | conn.py:394] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2023-07-04 23:49:03,808 	 [INFO | conn.py:410] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-07-04 23:49:03,808 	 [DEBUG | client_async.py:283] > Node bootstrap-0 connected
2023-07-04 23:49:03,808 	 [DEBUG | parser.py:59] > Sending request ApiVersionRequest_v0()
2023-07-04 23:49:03,808 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 1: ApiVersionRequest_v0()
2023-07-04 23:49:03,909 	 [DEBUG | parser.py:59] > Sending request MetadataRequest_v0(topics=[])
2023-07-04 23:49:03,910 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 2: MetadataRequest_v0(topics=[])
2023-07-04 23:49:03,910 	 [DEBUG | parser.py:139] > Received correlation id: 1
2023-07-04 23:49:03,910 	 [DEBUG | parser.py:166] > Processing response ApiVersionResponse_v0
2023-07-04 23:49:03,910 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 1 (102.25367546081543 ms): ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=9), (api_key=1, min_version=0, max_version=12), (api_key=2, min_version=0, max_version=7), (api_key=3, min_version=0, max_version=11), (api_key=4, min_version=0, max_version=5), (api_key=5, min_version=0, max_version=3), (api_key=6, min_version=0, max_version=7), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=8), (api_key=9, min_version=0, max_version=8), (api_key=10, min_version=0, max_version=4), (api_key=11, min_version=0, max_version=7), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=4), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=4), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=4), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=3), (api_key=25, min_version=0, max_version=3), (api_key=26, min_version=0, max_version=3), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=3), (api_key=29, min_version=0, max_version=2), (api_key=30, min_version=0, max_version=2), (api_key=31, min_version=0, max_version=2), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=2), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=2), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=2), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=0), (api_key=57, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=0), (api_key=61, min_version=0, max_version=0), (api_key=65, min_version=0, max_version=0), (api_key=66, min_version=0, max_version=0), (api_key=67, min_version=0, max_version=0)])
2023-07-04 23:49:03,913 	 [DEBUG | parser.py:139] > Received correlation id: 2
2023-07-04 23:49:03,914 	 [DEBUG | parser.py:166] > Processing response MetadataResponse_v0
2023-07-04 23:49:03,914 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 2 (4.424810409545898 ms): MetadataResponse_v0(brokers=[(node_id=1001, host='localhost', port=9092)], topics=[(error_code=0, topic='transaction_topic', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='test_topic2', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='__consumer_offsets', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=10, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=20, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=40, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=30, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=9, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=39, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=11, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=31, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=13, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=18, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=22, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=8, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=32, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=43, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=29, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=34, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=1, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=6, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=41, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=27, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=48, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=5, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=15, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=35, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=25, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=46, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=26, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=36, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=44, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=16, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=37, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=17, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=45, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=3, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=4, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=24, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=38, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=33, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=23, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=28, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=2, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=12, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=19, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=14, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=47, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=49, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=42, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=7, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=21, leader=1001, replicas=[1001], isr=[1001])])])
2023-07-04 23:49:03,914 	 [INFO | conn.py:1267] > Broker version identified as 2.5.0
2023-07-04 23:49:03,914 	 [INFO | conn.py:1268] > Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name bufferpool-wait-time
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name batch-size
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name compression-rate
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name queue-time
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name produce-throttle-time
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name records-per-request
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name bytes
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name record-retries
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name errors
2023-07-04 23:49:03,915 	 [DEBUG | metrics.py:156] > Added sensor with name record-size-max
2023-07-04 23:49:03,915 	 [DEBUG | sender.py:55] > Starting Kafka producer I/O thread.
2023-07-04 23:49:03,915 	 [DEBUG | kafka.py:418] > Kafka producer started
2023-07-04 23:49:03,915 	 [DEBUG | client_async.py:837] > Sending metadata request MetadataRequest_v1(topics=NULL) to node bootstrap-0
2023-07-04 23:49:03,916 	 [INFO | transaction_producer.py:36] > Successfully initialized __init__ in SimulationKafkaProducer class!
2023-07-04 23:49:03,916 	 [DEBUG | parser.py:59] > Sending request MetadataRequest_v1(topics=NULL)
2023-07-04 23:49:03,916 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 3: MetadataRequest_v1(topics=NULL)
2023-07-04 23:49:03,917 	 [DEBUG | parser.py:139] > Received correlation id: 3
2023-07-04 23:49:03,917 	 [DEBUG | parser.py:166] > Processing response MetadataResponse_v1
2023-07-04 23:49:03,918 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 3 (2.009868621826172 ms): MetadataResponse_v1(brokers=[(node_id=1001, host='localhost', port=9092, rack=None)], controller_id=1001, topics=[(error_code=0, topic='transaction_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='test_topic2', is_internal=False, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='__consumer_offsets', is_internal=True, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=10, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=20, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=40, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=30, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=9, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=39, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=11, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=31, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=13, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=18, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=22, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=8, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=32, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=43, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=29, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=34, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=1, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=6, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=41, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=27, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=48, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=5, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=15, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=35, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=25, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=46, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=26, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=36, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=44, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=16, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=37, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=17, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=45, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=3, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=4, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=24, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=38, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=33, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=23, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=28, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=2, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=12, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=19, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=14, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=47, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=49, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=42, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=7, leader=1001, replicas=[1001], isr=[1001]), (error_code=0, partition=21, leader=1001, replicas=[1001], isr=[1001])])])
2023-07-04 23:49:03,918 	 [DEBUG | cluster.py:325] > Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 3, groups: 0)
2023-07-04 23:49:03,921 	 [DEBUG | kafka.py:599] > Sending (key=None value='transaction_id,customer_id,transaction_type,amount,currency,transaction_date\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:03,921 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:03,921 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:49:03,921 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:49:03,921 	 [DEBUG | sender.py:109] > Node 1001 not ready; delaying produce of accumulated batch
2023-07-04 23:49:03,922 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:03,922 	 [DEBUG | client_async.py:374] > Initiating connection to node 1001 at localhost:9092
2023-07-04 23:49:03,922 	 [DEBUG | metrics.py:156] > Added sensor with name node-1001.bytes-sent
2023-07-04 23:49:03,922 	 [DEBUG | metrics.py:156] > Added sensor with name node-1001.bytes-received
2023-07-04 23:49:03,922 	 [DEBUG | metrics.py:156] > Added sensor with name node-1001.latency
2023-07-04 23:49:03,922 	 [DEBUG | conn.py:368] > <BrokerConnection node_id=1001 host=localhost:9092 <disconnected> [unspecified None]>: creating new socket
2023-07-04 23:49:03,922 	 [DEBUG | conn.py:374] > <BrokerConnection node_id=1001 host=localhost:9092 <disconnected> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2023-07-04 23:49:03,922 	 [INFO | conn.py:380] > <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-07-04 23:49:03,922 	 [DEBUG | sender.py:109] > Node 1001 not ready; delaying produce of accumulated batch
2023-07-04 23:49:03,923 	 [DEBUG | conn.py:394] > <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: established TCP connection
2023-07-04 23:49:03,923 	 [INFO | conn.py:410] > <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-07-04 23:49:03,923 	 [DEBUG | client_async.py:283] > Node 1001 connected
2023-07-04 23:49:03,923 	 [INFO | conn.py:919] > <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-07-04 23:49:03,923 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.records-per-batch
2023-07-04 23:49:03,923 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.bytes
2023-07-04 23:49:03,923 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.compression-rate
2023-07-04 23:49:03,923 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.record-retries
2023-07-04 23:49:03,923 	 [DEBUG | metrics.py:156] > Added sensor with name topic.transaction_topic.record-errors
2023-07-04 23:49:03,923 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:49:03,923 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02O\x19\x8d\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaau\xb1\x00\x00\x01\x89"\xaau\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])}
2023-07-04 23:49:03,924 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02O\x19\x8d\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaau\xb1\x00\x00\x01\x89"\xaau\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])
2023-07-04 23:49:03,924 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02O\x19\x8d\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaau\xb1\x00\x00\x01\x89"\xaau\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])
2023-07-04 23:49:03,924 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 1: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00\x00\x00\x02O\x19\x8d\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaau\xb1\x00\x00\x01\x89"\xaau\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\xae\x01\x00\x00\x00\x01\xa0\x01"transaction_id,customer_id,tra...')])])
2023-07-04 23:49:03,963 	 [DEBUG | parser.py:139] > Received correlation id: 1
2023-07-04 23:49:03,963 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:49:03,963 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 1 (39.80612754821777 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=103, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:49:03,964 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=103, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:49:03,964 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 103 log start offset 0 and error None.
2023-07-04 23:49:03,964 	 [INFO | transaction_producer.py:41] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:49:04,020 	 [DEBUG | client_async.py:837] > Sending metadata request MetadataRequest_v1(topics=['transaction_topic']) to node 1001
2023-07-04 23:49:04,020 	 [DEBUG | parser.py:59] > Sending request MetadataRequest_v1(topics=['transaction_topic'])
2023-07-04 23:49:04,020 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 2: MetadataRequest_v1(topics=['transaction_topic'])
2023-07-04 23:49:04,024 	 [DEBUG | parser.py:139] > Received correlation id: 2
2023-07-04 23:49:04,024 	 [DEBUG | parser.py:166] > Processing response MetadataResponse_v1
2023-07-04 23:49:04,024 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 2 (4.147052764892578 ms): MetadataResponse_v1(brokers=[(node_id=1001, host='localhost', port=9092, rack=None)], controller_id=1001, topics=[(error_code=0, topic='transaction_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])])])
2023-07-04 23:49:04,024 	 [DEBUG | cluster.py:325] > Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, groups: 0)
2023-07-04 23:49:04,965 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000001,2506,in,509.89,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:04,966 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:04,966 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:49:04,967 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:49:04,967 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:49:04,967 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:04,967 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02Fmk\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaay\xc6\x00\x00\x01\x89"\xaay\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])}
2023-07-04 23:49:04,968 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02Fmk\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaay\xc6\x00\x00\x01\x89"\xaay\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])
2023-07-04 23:49:04,968 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02Fmk\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaay\xc6\x00\x00\x01\x89"\xaay\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])
2023-07-04 23:49:04,968 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 3: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00a\x00\x00\x00\x00\x02Fmk\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaay\xc6\x00\x00\x01\x89"\xaay\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01^\x00\x00\x00\x01R"1000001,2506,in,509.89,EUR,2022-...')])])
2023-07-04 23:49:04,977 	 [DEBUG | parser.py:139] > Received correlation id: 3
2023-07-04 23:49:04,977 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:49:04,977 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 3 (9.307861328125 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=104, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:49:04,978 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=104, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:49:04,978 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 104 log start offset 0 and error None.
2023-07-04 23:49:04,978 	 [INFO | transaction_producer.py:41] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:49:05,980 	 [DEBUG | kafka.py:599] > Sending (key=None value='1000003,2373,out,248.63,EUR,2022-01-01\n' headers=[]) to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:05,981 	 [DEBUG | record_accumulator.py:242] > Allocating a new 16384 byte message buffer for TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:05,981 	 [DEBUG | kafka.py:606] > Waking up the sender since TopicPartition(topic='transaction_topic', partition=0) is either full or getting a new batch
2023-07-04 23:49:05,981 	 [DEBUG | kafka.py:646] > Flushing accumulated records in producer.
2023-07-04 23:49:05,981 	 [DEBUG | sender.py:141] > Nodes with data ready to send: {1001}
2023-07-04 23:49:05,982 	 [DEBUG | record_accumulator.py:526] > Waiting on produce to TopicPartition(topic='transaction_topic', partition=0)
2023-07-04 23:49:05,982 	 [DEBUG | sender.py:142] > Created 1 produce requests: {1001: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02Fs\t\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaa}\xbd\x00\x00\x01\x89"\xaa}\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])}
2023-07-04 23:49:05,982 	 [DEBUG | sender.py:147] > Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02Fs\t\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaa}\xbd\x00\x00\x01\x89"\xaa}\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])
2023-07-04 23:49:05,982 	 [DEBUG | parser.py:59] > Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02Fs\t\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaa}\xbd\x00\x00\x01\x89"\xaa}\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])
2023-07-04 23:49:05,982 	 [DEBUG | conn.py:972] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Request 4: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='transaction_topic', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00\x00\x02Fs\t\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x89"\xaa}\xbd\x00\x00\x01\x89"\xaa}\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01`\x00\x00\x00\x01T"1000003,2373,out,248.63,EUR,2022...')])])
2023-07-04 23:49:05,986 	 [DEBUG | parser.py:139] > Received correlation id: 4
2023-07-04 23:49:05,986 	 [DEBUG | parser.py:166] > Processing response ProduceResponse_v7
2023-07-04 23:49:05,986 	 [DEBUG | conn.py:1074] > <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]> Response 4 (4.132986068725586 ms): ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=105, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:49:05,986 	 [DEBUG | sender.py:191] > Parsing produce response: ProduceResponse_v7(topics=[(topic='transaction_topic', partitions=[(partition=0, error_code=0, offset=105, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
2023-07-04 23:49:05,986 	 [DEBUG | record_accumulator.py:73] > Produced messages to topic-partition TopicPartition(topic='transaction_topic', partition=0) with base offset 105 log start offset 0 and error None.
2023-07-04 23:49:05,987 	 [INFO | transaction_producer.py:41] > Succesfully sent message to topic: transaction_topic
2023-07-04 23:49:06,106 	 [INFO | kafka.py:483] > Closing the Kafka producer with 0 secs timeout.
2023-07-04 23:49:06,106 	 [INFO | kafka.py:499] > Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2023-07-04 23:49:06,106 	 [DEBUG | kafka.py:514] > The Kafka producer has closed.
